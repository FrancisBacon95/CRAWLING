{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1. 검색어 하고 재생수 기준으로 네이버 tv에서 띄움.\n",
    "- 2. item이 없는 페이지 -1까지의 페이지 index를 저장한다.\n",
    "- 3. 저장된 페이지 index 범위 내에서 작업한다.\n",
    "- 3. tv프로그램 리스트에 있는 채널들의 동영상의 (프로그램 명,제목,날짜,설명, 해시태그는 나중에) 정보를 가져온다. \n",
    "- 4. 가져온 데이터를 날짜 순으로 정렬한 뒤 엑셀로 저장 \n",
    "\n",
    "이 과정만 파이썬 코드로 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네이버 TV 크롤링\n",
    "\n",
    "## 1.1 사용 패키지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 이용방법\n",
    "\n",
    "- 서버에서 Naver_Blog_Crawler/TV_Crawler.ipynb 실행\n",
    "\n",
    "- 키워드 INPUT : ../Naver_Blog_Crawler/name.txt\n",
    "\n",
    "- OUTPUT (CSV) : Naver_Blog_Crawler/data/\"keyword\".txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 출력물\n",
    "\n",
    "#### 1) 변수 설명\n",
    "\n",
    "    - program : 해당 영상의 프로그램 이름\n",
    "    - title : 해당 영상 제목\n",
    "    - hit : 해당 영상 조회수\n",
    "    - date : 해당 영상 게시 날짜\n",
    "    - url : 해당 영상 url 주소"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 코드"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 입력란"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_df=pd.read_csv(\"네이버TV 키워드.csv\",encoding='ms949')\n",
    "keywordlist=keyword_df['품명'].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - 코드 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 키워드에 대한 자료가 몇 페이지까지 있는지를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바지락 32\n"
     ]
    }
   ],
   "source": [
    "tv_pro_pd=pd.read_csv(\"TVprogram.csv\",encoding='ms949')\n",
    "tv_pro_list=tv_pro_pd['프로그램명'].values.tolist()\n",
    "\n",
    "index_list = {}\n",
    "#각 키워드에 대한 반복문 실행\n",
    "for keyword in keywordlist:\n",
    "\n",
    "    page_index=1\n",
    "    stop_index=0\n",
    "    while True:\n",
    "        response=requests.get(\"https://tv.naver.com/search/clip?query=\"+keyword+\"&sort=date&page=\"+str(page_index)+\"&isTag=false\")\n",
    "        html=response.text\n",
    "        soup=BeautifulSoup(html,'html.parser')  \n",
    "        tag=soup.find(\"div\",{\"class\":\"src_wrap\"}).text\n",
    "        tag_text_list=tag.split(\"\\n\")\n",
    "        #print(page_index)\n",
    "        #네이버 TV는 자료가 있는 만큼 페이지 수를 제공하는 게 아니라 계속 증가한다.\n",
    "        #다만 자료가 없을 경우는 아래의 문장을 출력하기 때문에 그것으로 자료를 다 끌어왔음을 확인한다.\n",
    "        if '- 단어의 철자가 정확한지 확인해주세요.' in tag_text_list :\n",
    "            stop_index=page_index-1\n",
    "            break\n",
    "        page_index+=1\n",
    "    index_list[keyword] = stop_index\n",
    "    print(keyword+\" \"+str(stop_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 키워드에 대한 페이지 수가 정해지면 그만큼만 크롤링을 진행한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "바지락\n"
     ]
    }
   ],
   "source": [
    "for keyword in keywordlist:\n",
    "    stop_index = index_list[keyword]\n",
    "    print(keyword)\n",
    "    program_list=[]\n",
    "    title_list=[]\n",
    "    hit_list=[]\n",
    "    date_list=[]\n",
    "    url_list=[]\n",
    "    for page_index in range(1,stop_index):\n",
    "        response=requests.get(\"https://tv.naver.com/search/clip?query=\"+keyword+\"&sort=date&page=\"+str(page_index)+\"&isTag=false\")\n",
    "        html=response.text\n",
    "        soup=BeautifulSoup(html,'html.parser')\n",
    "        tag_list=soup.find_all(\"div\",{\"class\":\"thl_a\"})\n",
    "        for tag in tag_list :\n",
    "            publisher = tag.find(\"span\",{\"class\":\"ch_txt\"}).find(\"a\")\n",
    "            if publisher.text in tv_pro_list:\n",
    "                url_post=\"http://tv.naver.com\"+tag.find(\"a\",href=True)['href']\n",
    "                url_post1=url_post.split(\"?\")[0]\n",
    "                response_post=requests.get(url_post)\n",
    "                html_post=response_post.text\n",
    "                soup_post=BeautifulSoup(html_post,'html.parser')\n",
    "    \n",
    "                title=soup_post.find(\"h3\",{\"class\":\"_clipTitle\"}).text\n",
    "                date=soup_post.find(\"span\",{\"class\":\"date\"}).text\n",
    "                hit=soup_post.find(\"span\",{\"class\":\"play\"}).text\n",
    "            \n",
    "                #soup_hash=soup_post.find(\"ul\",{\"class\":\"list_hash\"})\n",
    "                #one_post_hash=soup_hash.text.split('\\n')[1:-1]\n",
    "                #print(soup_hash)\n",
    "            \n",
    "                date1=date.replace(\"등록\",\"\")\n",
    "                hit1=hit.replace(\"        \",\"\").replace(\"\\n\",\"\").replace(\"재생수\",\"\")\n",
    "\n",
    "                title_list.append(title)\n",
    "                #print(title)\n",
    "                date_list.append(date1)\n",
    "                hit_list.append(hit1)\n",
    "                #hash_list.append(one_post_hash)\n",
    "                program_list.append(publisher.text)\n",
    "                url_list.append(url_post1)\n",
    "                \n",
    "                \n",
    "    finish=pd.DataFrame([program_list,title_list,hit_list,date_list,url_list]).T\n",
    "    finish.columns=['프로그램','제목','조회수','날짜','URL']\n",
    "    finish1=finish.drop_duplicates()\n",
    "    finish1.sort_values(by='날짜').to_csv(keyword+\"_네이버TV.csv\",encoding='utf-8',index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
